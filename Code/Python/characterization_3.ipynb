{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided script is designed for the analysis of collective behavior in nematodes. \n",
    "\n",
    "Here we conduct the analysis comparing all the strains belonging to the divergent data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.draw import circle_perimeter\n",
    "from math import sqrt\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.filters import threshold_otsu\n",
    "from tabulate import tabulate\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rcParams\n",
    "import h5py    # for reading HDF5 files \n",
    "import cv2     # for image conversion\n",
    "import re    # use it to sort but not sure what it is!\n",
    "from scipy.stats import zscore\n",
    "from skimage import draw, measure\n",
    "import pywt\n",
    "from scipy.spatial.distance import cdist\n",
    "import seaborn as sns\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.colors as colors\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage import color\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set infromation overview: ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Divergent Sets:\n",
    "\n",
    "    Consists of 12 genotypically distinct strains. These are strains that are further apart on the phenotypic tree. \n",
    "    Ideal for determining broad-sense heritability with repeated measurements of specific phenotypes.\n",
    "    This allows us to look into the relationship between the behavior and the genetic makeup. \n",
    "\n",
    "2. Mapping Sets:\n",
    "\n",
    "    Comprises 48 strains suitable for collecting phenotype data for broad diversity or genome-wide association studies.\n",
    "    Using multiple strain sets can enhance the statistical strength in genome-wide association studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling and processing image data stored in HDF5 files ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow: ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The script sets the paths to your HDF5 files and the directory for extracted frames.\n",
    "\n",
    "2. It ensures the output directory exists for each strain and each experiment.\n",
    "\n",
    "3. It retrieves the paths of HDF5 files for each strain and creates corresponding output directories.\n",
    "\n",
    "4. It extracts frames from HDF5 files and saves them in the respective experiment subfolders.\n",
    "\n",
    "5. It loads images from these output directories for further analysis.\n",
    "\n",
    "6. It creates a dictionary labels_strain_list mapping experiment labels to the loaded images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions: ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ensure_directory_exists: Ensures a directory exists, and if not, creates it.\n",
    "\n",
    "extract_experiment_name: Extracts the experiment name from the HDF5 file name. Adjust the logic here depending on your file naming convention.\n",
    "\n",
    "create_output_directories_for_experiments: Creates output directories for each experiment under each strain.\n",
    "\n",
    "extract_frames_from_hdf5: Extracts frames from an HDF5 file and saves them in the specified output directory.\n",
    "\n",
    "load_images_from_folder: Loads images from a given folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_directory_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def extract_experiment_name(file_path):\n",
    "    # Assuming the experiment's name is part of the file's name\n",
    "    base_name = os.path.basename(file_path)\n",
    "    name_parts = base_name.split('_')\n",
    "    experiment_name = '_'.join(name_parts[:-1])  # Exclude the extension and any other parts\n",
    "    return experiment_name\n",
    "\n",
    "def create_output_directories_for_experiments(root_path):\n",
    "    output_dirs = {}\n",
    "    strain_folders = [d for d in os.listdir(root_path) if os.path.isdir(os.path.join(root_path, d))]\n",
    "    \n",
    "    for strain in strain_folders:\n",
    "        hdf5_files = glob.glob(os.path.join(root_path, strain, '*.hdf5'))\n",
    "        for file_path in hdf5_files:\n",
    "            experiment_name = extract_experiment_name(file_path)\n",
    "            output_dir = os.path.join(root_path, strain, experiment_name)\n",
    "            ensure_directory_exists(output_dir)\n",
    "            output_dirs[file_path] = output_dir\n",
    "\n",
    "    return output_dirs\n",
    "\n",
    "def extract_frames_from_hdf5(file_path, output_directory, step=500):\n",
    "    with h5py.File(file_path, 'r') as hdf:\n",
    "        img_ds2 = hdf['/mask']\n",
    "        for i in range(0, img_ds2.shape[0], step):\n",
    "            name = f\"{i:06d}.jpg\"\n",
    "            cv2.imwrite(os.path.join(output_directory, name), img_ds2[i, :])\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    all_images = []\n",
    "    image_files = [f for f in os.listdir(folder) if f.endswith(\".jpg\")]\n",
    "    for filename in image_files:\n",
    "        filepath = os.path.join(folder, filename)\n",
    "        image = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is not None:\n",
    "            all_images.append(image)\n",
    "    return all_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "root_path = '/Volumes/TOSHIBA_EXT/Phenotype_features_collective/Data'\n",
    "output_root_path = '/Volumes/TOSHIBA_EXT/Phenotype_features_collective/ExtractedFrames'\n",
    "\n",
    "# Ensure the output root folder exists\n",
    "ensure_directory_exists(output_root_path)\n",
    "\n",
    "# Create output directories for each experiment under each strain\n",
    "output_directories = create_output_directories_for_experiments(root_path)\n",
    "\n",
    "# Extract frames and load images\n",
    "labels_strain_list = {}\n",
    "for file_path, output_dir in output_directories.items():\n",
    "    extract_frames_from_hdf5(file_path, output_dir)\n",
    "    images = load_images_from_folder(output_dir)\n",
    "    experiment_label = extract_experiment_name(file_path)\n",
    "    labels_strain_list[experiment_label] = images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collectiveNematode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
