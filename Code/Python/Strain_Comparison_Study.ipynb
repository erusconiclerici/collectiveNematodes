{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided script is designed for the analysis of collective behavior in nematodes. \n",
    "\n",
    "Here we conduct the analysis comparing all the strains belonging to the divergent data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.draw import circle_perimeter\n",
    "from math import sqrt\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.filters import threshold_otsu\n",
    "from tabulate import tabulate\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rcParams\n",
    "import h5py    # for reading HDF5 files \n",
    "import cv2     # for image conversion\n",
    "import re    # use it to sort but not sure what it is!\n",
    "from scipy.stats import zscore\n",
    "from skimage import draw, measure\n",
    "import pywt\n",
    "from scipy.spatial.distance import cdist\n",
    "import seaborn as sns\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.colors as colors\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage import color\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set infromation overview: ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Divergent Sets:\n",
    "\n",
    "    Consists of 12 genotypically distinct strains. These are strains that are further apart on the phenotypic tree. \n",
    "    Ideal for determining broad-sense heritability with repeated measurements of specific phenotypes.\n",
    "    This allows us to look into the relationship between the behavior and the genetic makeup. \n",
    "\n",
    "2. Mapping Sets:\n",
    "\n",
    "    Comprises 48 strains suitable for collecting phenotype data for broad diversity or genome-wide association studies.\n",
    "    Using multiple strain sets can enhance the statistical strength in genome-wide association studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow: Handling and processing image data stored in HDF5 files ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In hdf5_frames_extractor: \n",
    "\n",
    "1. The script sets the paths to your HDF5 files and the directory for extracted frames.\n",
    "\n",
    "2. It ensures the output directory exists for each strain and each experiment.\n",
    "\n",
    "3. It retrieves the paths of HDF5 files for each strain and creates corresponding output directories.\n",
    "\n",
    "4. It extracts frames from HDF5 files and saves them in the respective experiment subfolders.\n",
    "\n",
    "Strain_comparison_study: \n",
    "\n",
    "5. Load Images: Use the load_images_from_folder function to load frames from each experiment.\n",
    "\n",
    "6. It creates a dictionary labels_strain_list mapping experiment labels to the loaded images.\n",
    "\n",
    "7. Feature Extraction: Write functions to extract the necessary features from each frame.\n",
    "\n",
    "8. Aggregate and Analyze: Aggregate the features per experiment, and then perform statistical analyses and visualizations.\n",
    "\n",
    "9. Comparison: Compare these features across different strains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions: ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract_experiment_name: Extracts the experiment name from a given file or folder path.\n",
    "\n",
    "load_images_from_folder: Loads all images in the specified folder and returns a list of images.\n",
    "\n",
    "labels_strain_list: A dictionary that maps each experiment's label to its corresponding images. This is created by iterating through each strain's folder and then through each experiment's subfolder within the strain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_experiment_name(file_path):\n",
    "    # Assuming the experiment's name is part of the file's name\n",
    "    base_name = os.path.basename(file_path)\n",
    "    name_parts = base_name.split('_')\n",
    "    experiment_name = '_'.join(name_parts[:-1])  # Exclude the extension and any other parts\n",
    "    return experiment_name\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    all_images = []\n",
    "    image_files = [f for f in os.listdir(folder) if f.endswith(\".jpg\")]\n",
    "    for filename in image_files:\n",
    "        filepath = os.path.join(folder, filename)\n",
    "        image = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is not None:\n",
    "            all_images.append(image)\n",
    "    return all_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Loading ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the root path where the extracted images are stored\n",
    "output_root_path = '/Volumes/TOSHIBA_EXT/Phenotype_features_collective/ExtractedFrames'\n",
    "\n",
    "# Create a dictionary to map experiment labels to images\n",
    "labels_strain_list = {}\n",
    "strain_folders = [d for d in os.listdir(output_root_path) if os.path.isdir(os.path.join(output_root_path, d))]\n",
    "\n",
    "for strain in strain_folders:\n",
    "    experiment_folders = [os.path.join(output_root_path, strain, e) for e in os.listdir(os.path.join(output_root_path, strain)) if os.path.isdir(os.path.join(output_root_path, strain, e))]\n",
    "    for folder in experiment_folders:\n",
    "        images = load_images_from_folder(folder)\n",
    "        experiment_label = extract_experiment_name(folder)\n",
    "        labels_strain_list[experiment_label] = images\n",
    "\n",
    "# Now 'labels_strain_list' contains the mapping of experiment labels to the loaded images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collectiveNematode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
