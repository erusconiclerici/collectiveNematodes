{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided script is designed for the analysis of collective behavior in nematodes. \n",
    "\n",
    "Here we conduct the analysis comparing all the strains belonging to the divergent data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from math import sqrt\n",
    "from matplotlib import rcParams\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import zscore\n",
    "from skimage import color\n",
    "from skimage import draw, measure\n",
    "from skimage.draw import circle_perimeter\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.io import imread\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.transform import resize\n",
    "from sklearn.cluster import KMeans\n",
    "from tabulate import tabulate\n",
    "import cv2     # for image conversion\n",
    "import glob\n",
    "import h5py    # for reading HDF5 files \n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pywt\n",
    "import re    # use it to sort but not sure what it is!\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set infromation overview: ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Divergent Sets:\n",
    "\n",
    "    Consists of 12 genotypically distinct strains. These are strains that are further apart on the phenotypic tree. \n",
    "    Ideal for determining broad-sense heritability with repeated measurements of specific phenotypes.\n",
    "    This allows us to look into the relationship between the behavior and the genetic makeup. \n",
    "\n",
    "2. Mapping Sets:\n",
    "\n",
    "    Comprises 48 strains suitable for collecting phenotype data for broad diversity or genome-wide association studies.\n",
    "    Using multiple strain sets can enhance the statistical strength in genome-wide association studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow: Handling and processing image data stored in HDF5 files ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General steps: \n",
    "1. Frame extraction from hdf5 files and saving \n",
    "\n",
    "2. Feature extraction from each frame \n",
    "\n",
    "3. Analysis of features \n",
    "\n",
    "More in detail: \n",
    "\n",
    "In hdf5_frames_extractor: \n",
    "\n",
    "1. The script sets the paths to your HDF5 files and the directory for extracted frames.\n",
    "\n",
    "2. It ensures the output directory exists for each strain and each experiment.\n",
    "\n",
    "3. It retrieves the paths of HDF5 files for each strain and creates corresponding output directories.\n",
    "\n",
    "4. It extracts frames from HDF5 files and saves them in the respective experiment subfolders.\n",
    "\n",
    "Strain_comparison_study: \n",
    "\n",
    "5. Load Images: Use the load_images_from_folder function to load frames from each experiment.\n",
    "\n",
    "6. It creates a dictionary labels_strain_list mapping experiment labels to the loaded images.\n",
    "\n",
    "7. Feature Extraction: Write functions to extract the necessary features from each frame.\n",
    "\n",
    "8. Aggregate and Analyze: Aggregate the features per experiment, and then perform statistical analyses and visualizations.\n",
    "\n",
    "9. Comparison: Compare these features across different strains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions: ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and selecting frames \n",
    "def select_frames(folder, num_frames):\n",
    "    \"\"\"\n",
    "    Select a specified number of frames from a folder.\n",
    "    \"\"\"\n",
    "    image_files = sorted(glob.glob(os.path.join(folder, '*.jpg')))\n",
    "    total_frames = len(image_files)\n",
    "\n",
    "    if total_frames <= num_frames:\n",
    "        return image_files\n",
    "\n",
    "    indices = np.linspace(0, total_frames - 1, num=num_frames, dtype=int)\n",
    "    return [image_files[i] for i in indices]\n",
    "\n",
    "def extract_experiment_name(file_path):\n",
    "    \"\"\"\n",
    "    Extract the experiment name from the file path.\n",
    "    \"\"\"\n",
    "    base_name = os.path.basename(file_path)\n",
    "    name_parts = base_name.split('_')\n",
    "    return '_'.join(name_parts[:-1])  # Exclude the extension\n",
    "\n",
    "def read_image(image_path, color_mode=cv2.IMREAD_GRAYSCALE):\n",
    "    \"\"\"\n",
    "    Reads an image from the given path in the specified color mode.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path, color_mode)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Could not read the image file {image_path}\")\n",
    "    return image\n",
    "\n",
    "# Normalizing images \n",
    "# def equalize_histogram(image):\n",
    "    if len(image.shape) == 3:  # Check if the image is colored (3 channels)\n",
    "        # Convert to YUV color space\n",
    "        yuv_img = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "        \n",
    "        # Equalize the histogram of the Y (luminance) channel\n",
    "        yuv_img[:, :, 0] = cv2.equalizeHist(yuv_img[:, :, 0])\n",
    "        \n",
    "        # Convert back to BGR color space\n",
    "        equalized_img = cv2.cvtColor(yuv_img, cv2.COLOR_YUV2BGR)\n",
    "    else:\n",
    "        # For grayscale images\n",
    "        equalized_img = cv2.equalizeHist(image)\n",
    "\n",
    "    return equalized_img\n",
    "\n",
    "\n",
    "# Noise filteirng and cleaning \n",
    "def segment_and_close_areas(image, threshold_value, closing_kernel_size=(15, 15)):\n",
    "    \"\"\"\n",
    "    Segment lighter areas in the image based on a threshold and close holes in white areas.\n",
    "    \n",
    "    Parameters:\n",
    "    - image: The input image to segment.\n",
    "    - threshold_value: The threshold value for segmentation.\n",
    "    - closing_kernel_size: The size of the kernel used for morphological closing.\n",
    "    \"\"\"\n",
    "    # Apply threshold to segment the image\n",
    "    _, thresh = cv2.threshold(image, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Define the closing kernel\n",
    "    closing_kernel = np.ones(closing_kernel_size, np.uint8)\n",
    "    \n",
    "    # Apply morphological closing\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, closing_kernel)\n",
    "    \n",
    "    # Further clean up using opening, if necessary\n",
    "    opening_kernel = np.ones((3, 3), np.uint8)\n",
    "    cleaned = cv2.morphologyEx(closed, cv2.MORPH_OPEN, opening_kernel)\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "def subtract_background(frame_path, num_background_frames=50):\n",
    "    \"\"\"\n",
    "    Subtracts the background from a frame by averaging a randomly selected number\n",
    "    of frames from the same folder and subtracting it from the frame.\n",
    "    \"\"\"\n",
    "    folder = os.path.dirname(frame_path)\n",
    "    frame_files = sorted(glob.glob(os.path.join(folder, '*.jpg')))\n",
    "\n",
    "    # Randomly select frames for background calculation\n",
    "    if len(frame_files) > num_background_frames:\n",
    "        selected_frames = random.sample(frame_files, num_background_frames)\n",
    "    else:\n",
    "        selected_frames = frame_files\n",
    "\n",
    "    # Ensure the selected frame is included in the background calculation\n",
    "    if frame_path not in selected_frames:\n",
    "        selected_frames.append(frame_path)\n",
    "\n",
    "    background = np.mean([read_image(f) for f in selected_frames], axis=0)\n",
    "\n",
    "    frame = read_image(frame_path)\n",
    "    subtracted = cv2.absdiff(frame.astype(np.uint8), background.astype(np.uint8))\n",
    "\n",
    "    return subtracted\n",
    "\n",
    "def apply_threshold(image, threshold_value):\n",
    "    \"\"\"\n",
    "    Applies thresholding to an image.\n",
    "    \"\"\"\n",
    "    _, thresh = cv2.threshold(image, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "    return thresh\n",
    "\n",
    "\n",
    "def calculate_features(image, frame_number, threshold_value=30):\n",
    "    \"\"\"\n",
    "    Calculate features for a given image and frame number after thresholding\n",
    "    and closing, ensuring correct handling of center of mass positions without\n",
    "    applying any unnecessary adjustments. Additionally, count the number of blobs.\n",
    "    \"\"\"\n",
    "    segmented = segment_and_close_areas(image, threshold_value)\n",
    "    labeled_areas = label(segmented)\n",
    "    properties = regionprops(labeled_areas)\n",
    "\n",
    "    features = []\n",
    "    blob_count = len(properties)  # Count the number of blobs detected\n",
    "\n",
    "    for prop in properties:\n",
    "        center_of_mass = prop.centroid\n",
    "        distance_from_center = np.linalg.norm(np.array([center_of_mass[1], center_of_mass[0]]) - np.array([image.shape[1] / 2, image.shape[0] / 2]))\n",
    "        features.append({\n",
    "            'frame': frame_number,\n",
    "            'center_of_mass': center_of_mass,\n",
    "            'distance_from_center': distance_from_center,\n",
    "            'area': prop.area,\n",
    "            'blob_count': blob_count  # Add blob count to each blob's features\n",
    "        })\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Loading ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Iterates over each strain folder.\n",
    "\n",
    "2. For each experiment within a strain, it selects a specified number of frames.\n",
    "\n",
    "3. Prints the selected frames for diagnostics.\n",
    "\n",
    "4. Extracts features from the selected frames.\n",
    "\n",
    "5. Loads the selected images and stores them in labels_strain_list.\n",
    "\n",
    "6. Prints the number of images loaded for each experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main analysis loop\n",
    "root_path = '/Volumes/TOSHIBA_EXT/Phenotype_features_collective/Data/ExtractedFrames'\n",
    "experiment_features = {}\n",
    "\n",
    "for strain_folder in os.listdir(root_path):\n",
    "    strain_path = os.path.join(root_path, strain_folder)\n",
    "    if os.path.isdir(strain_path):\n",
    "        experiment_features[strain_folder] = {}\n",
    "        for experiment_folder in os.listdir(strain_path):\n",
    "            experiment_path = os.path.join(strain_path, experiment_folder)\n",
    "            if os.path.isdir(experiment_path):\n",
    "                selected_frame_paths = select_frames(experiment_path, 3)\n",
    "                experiment_label = extract_experiment_name(experiment_path)\n",
    "                experiment_features[strain_folder][experiment_label] = []\n",
    "                for frame_number, frame_path in enumerate(selected_frame_paths):\n",
    "                    frame = cv2.imread(frame_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                    # Apply histogram equalization\n",
    "                    # equalized_frame = equalize_histogram(frame)\n",
    "\n",
    "                    # Process the equalized frame\n",
    "                    frame_features = calculate_features(frame, frame_number)\n",
    "                    experiment_features[strain_folder][experiment_label].append(frame_features)\n",
    "\n",
    "# Example usage of the structured data\n",
    "# print_structure(experiment_features) # Uncomment to print the structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check structure ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_structure(data_dict):\n",
    "    if not isinstance(data_dict, dict):\n",
    "        print(\"The data is not a dictionary.\")\n",
    "        return\n",
    "\n",
    "    for key, value in data_dict.items():\n",
    "        print(f\"Key: {key}\")\n",
    "        if isinstance(value, dict):\n",
    "            for subkey, subvalue in value.items():\n",
    "                print(f\"  Subkey: {subkey}\")\n",
    "                if isinstance(subvalue, dict):\n",
    "                    for subsubkey, subsubvalue in subvalue.items():\n",
    "                        print(f\"    Subsubkey: {subsubkey}, Value: {subsubvalue}\")\n",
    "                else:\n",
    "                    print(f\"  Value: {subvalue}\")\n",
    "        else:\n",
    "            print(f\"Value: {value}\")\n",
    "        print(\"-------\")  # Just to separate between entries for readability\n",
    "\n",
    "# Example usage\n",
    "print_structure(experiment_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To visualize one frame detected blobs ###\n",
    "I ahve added a close_area function that closes up the white areas but I am not sure if I need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from skimage.measure import label, regionprops\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Assuming all the other functions (read_image, subtract_background, etc.) are defined as provided\n",
    "\n",
    "def visualize_processing_and_results(frame_path, threshold_value=50):\n",
    "    \"\"\"\n",
    "    Visualizes the original frame, the frame after background subtraction and thresholding,\n",
    "    and the frame with the detected centers of mass overlayed, ensuring vertical positions are handled properly.\n",
    "    \"\"\"\n",
    "    original_image = read_image(frame_path, cv2.IMREAD_GRAYSCALE)\n",
    "    subtracted = subtract_background(frame_path)\n",
    "    segmented = segment_and_close_areas(subtracted, threshold_value)\n",
    "    labeled_areas = label(segmented)\n",
    "    properties = regionprops(labeled_areas)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "    # Original Image\n",
    "    ax[0].imshow(original_image, cmap='gray')\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    # Image after Background Subtraction and Histogram Equalization\n",
    "    ax[1].imshow(subtracted, cmap='gray')\n",
    "    ax[1].set_title('Background Subtracted')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    # Image with Centers of Mass\n",
    "    ax[2].imshow(segmented, cmap='gray')\n",
    "    for prop in properties:\n",
    "        # Use the original centroid coordinates directly for plotting\n",
    "        # This assumes y-coordinate adjustments were not necessary as they are already correct\n",
    "        center_of_mass = prop.centroid\n",
    "        circ = patches.Circle((center_of_mass[1], center_of_mass[0]), radius=5, edgecolor='red', facecolor='none')\n",
    "        ax[2].add_patch(circ)\n",
    "\n",
    "    ax[2].set_title('Centers of Mass Overlayed to Segmented Image')\n",
    "    ax[2].axis('off')\n",
    "\n",
    "    ax[3].imshow(segmented, cmap='gray')\n",
    "    ax[3].set_title('Background Subtracted')\n",
    "    ax[3].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "frame_path = '/Volumes/TOSHIBA_EXT/Phenotype_features_collective/Data/ExtractedFrames/MY23/1.2_7_nic252_e2_my23_6c_Set0_Pos0_Ch6_15012018_165449/000000.jpg'  \n",
    "visualize_processing_and_results(frame_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series for Each Strain (All Experiments) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we selct one strain and one feature and compute the time series for all videos belonging to that strain. Each point in the time series is the average of the feature for a specific frame. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHANGE FILL IN ALPHA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "#636EFA"
         },
         "mode": "lines+markers",
         "name": "Video 1 Mean",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675
         ],
         "y": [
          36,
          38,
          35,
          35,
          35,
          33,
          34,
          37,
          36,
          36,
          34,
          36,
          36,
          32,
          34,
          38,
          36,
          39,
          38,
          42,
          43,
          40,
          39,
          37,
          41,
          37,
          39,
          40,
          38,
          38,
          39,
          34,
          32,
          33,
          37,
          36,
          34,
          34,
          34,
          34,
          33,
          38,
          27,
          28,
          28,
          29,
          31,
          34,
          36,
          36,
          36,
          33,
          37,
          35,
          37,
          36,
          38,
          30,
          39,
          39,
          41,
          40,
          42,
          39,
          36,
          32,
          30,
          29,
          33,
          32,
          29,
          36,
          27,
          31,
          31,
          37,
          36,
          39,
          35,
          38,
          33,
          27,
          28,
          31,
          32,
          30,
          33,
          33,
          31,
          33,
          32,
          30,
          27,
          32,
          32,
          34,
          36,
          35,
          34,
          34,
          30,
          34,
          35,
          38,
          36,
          34,
          36,
          35,
          35,
          34,
          32,
          33,
          32,
          33,
          35,
          32,
          35,
          37,
          38,
          36,
          31,
          32,
          37,
          36,
          35,
          32,
          34,
          30,
          35,
          39,
          34,
          37,
          35,
          37,
          36,
          41,
          39,
          40,
          40,
          42,
          38,
          37,
          41,
          35,
          36,
          34,
          34,
          34,
          32,
          36,
          33,
          35,
          33,
          41,
          36,
          34,
          32,
          33,
          33,
          32,
          33,
          33,
          34,
          36,
          34,
          36,
          31,
          33,
          32,
          28,
          34,
          32,
          35,
          37,
          36,
          38,
          35,
          36,
          37,
          31,
          28,
          29,
          31,
          31,
          35,
          38,
          35,
          32,
          34,
          35,
          33,
          33,
          32,
          32,
          32,
          33,
          31,
          30,
          29,
          33,
          29,
          29,
          29,
          33,
          33,
          32,
          30,
          29,
          30,
          30,
          32,
          34,
          30,
          34,
          32,
          30,
          30,
          31,
          32,
          30,
          36,
          38,
          31,
          31,
          32,
          32,
          32,
          34,
          43,
          35,
          36,
          35,
          37,
          38,
          37,
          31,
          34,
          34,
          34,
          39,
          40,
          39,
          41,
          41,
          46,
          40,
          37,
          37,
          36,
          39,
          37,
          36,
          36,
          34,
          34,
          33,
          37,
          37,
          39,
          35,
          33,
          35,
          37,
          35,
          36,
          34,
          36,
          30,
          37,
          36,
          36,
          29,
          31,
          38,
          41,
          40,
          40,
          38,
          37,
          37,
          36,
          37,
          37,
          37,
          35,
          38,
          37,
          38,
          40,
          37,
          38,
          39,
          38,
          36,
          37,
          38,
          36,
          37,
          36,
          37,
          38,
          37,
          37,
          38,
          40,
          39,
          37,
          40,
          38,
          31,
          32,
          35,
          31,
          33,
          36,
          41,
          36,
          33,
          37,
          40,
          32,
          34,
          34,
          35,
          36,
          35,
          36,
          36,
          33,
          37,
          30,
          32,
          33,
          36,
          35,
          35,
          32,
          29,
          31,
          28,
          29,
          29,
          31,
          33,
          35,
          36,
          32,
          33,
          29,
          29,
          30,
          29,
          30,
          32,
          32,
          34,
          35,
          31,
          31,
          28,
          27,
          27,
          29,
          27,
          26,
          28,
          31,
          26,
          26,
          29,
          30,
          26,
          29,
          26,
          34,
          30,
          30,
          28,
          33,
          33,
          28,
          33,
          29,
          30,
          27,
          27,
          29,
          30,
          32,
          30,
          27,
          27,
          29,
          25,
          27,
          28,
          28,
          27,
          31,
          28,
          22,
          24,
          24,
          32,
          29,
          30,
          30,
          30,
          26,
          28,
          30,
          29,
          25,
          27,
          27,
          28,
          28,
          28,
          27,
          28,
          28,
          28,
          27,
          31,
          28,
          28,
          24,
          27,
          28,
          30,
          28,
          29,
          30,
          29,
          29,
          28,
          26,
          27,
          28,
          28,
          30,
          26,
          26,
          20,
          22,
          24,
          23,
          23,
          21,
          24,
          25,
          27,
          24,
          28,
          25,
          24,
          26,
          26,
          23,
          27,
          25,
          27,
          29,
          27,
          28,
          25,
          28,
          25,
          29,
          27,
          28,
          27,
          25,
          27,
          29,
          27,
          26,
          25,
          28,
          27,
          25,
          27,
          27,
          30,
          28,
          25,
          28,
          26,
          27,
          24,
          27,
          27,
          27,
          23,
          26,
          26,
          26,
          25,
          25,
          24,
          24,
          26,
          26,
          25,
          25,
          25,
          24,
          25,
          25,
          23,
          25,
          25,
          25,
          24,
          24,
          22,
          21,
          17,
          18,
          18,
          21,
          22,
          23,
          23,
          22,
          22,
          21,
          21,
          22,
          22,
          26,
          22,
          25,
          23,
          25,
          24,
          25,
          22,
          24,
          23,
          22,
          20,
          21,
          23,
          24,
          23,
          23,
          25,
          24,
          24,
          24,
          22,
          24,
          27,
          24,
          24,
          22,
          24,
          24,
          24,
          25,
          23,
          24,
          25,
          25,
          24,
          26,
          23,
          25,
          23,
          22,
          23,
          25,
          22,
          24,
          23,
          20,
          22,
          25,
          23,
          22,
          23,
          20,
          21,
          22,
          28,
          27,
          26,
          26,
          25,
          25,
          26,
          25,
          26,
          26,
          21,
          21,
          21,
          18,
          19,
          22,
          22,
          24,
          24,
          25,
          25,
          27,
          24,
          25,
          25,
          26,
          25,
          22,
          19,
          24,
          24,
          22,
          23,
          24,
          21,
          22,
          24,
          21,
          23,
          22,
          24,
          22,
          22,
          23,
          20,
          20,
          21,
          21,
          23,
          22,
          22,
          21,
          21,
          21,
          21,
          22,
          24,
          22,
          22,
          22,
          20,
          20,
          21,
          20,
          20,
          22,
          21,
          20,
          20,
          19,
          19,
          18,
          17,
          18,
          17,
          17,
          16,
          15,
          17,
          16,
          17,
          18,
          19,
          20,
          20,
          23,
          23,
          21,
          22,
          22,
          19
         ]
        }
       ],
       "layout": {
        "hovermode": "closest",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Time Series of blob_count for Strain \"da609\""
        },
        "xaxis": {
         "range": [
          0,
          675
         ],
         "title": {
          "text": "Frame Number"
         }
        },
        "yaxis": {
         "title": {
          "text": "blob_count Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px  # Import Plotly Express\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "from skimage.measure import label, regionprops\n",
    "import random\n",
    "\n",
    "def subtract_background_from_video(video_folder, num_background_frames=50):\n",
    "    \"\"\"\n",
    "    Calculates the background for a video by averaging a specified number of frames.\n",
    "    \"\"\"\n",
    "    frame_files = sorted(glob.glob(os.path.join(video_folder, '*.jpg')))\n",
    "    selected_frames = random.sample(frame_files, min(len(frame_files), num_background_frames))\n",
    "\n",
    "    # Read and average the selected frames to compute the background\n",
    "    background_frames = [cv2.imread(f, cv2.IMREAD_GRAYSCALE) for f in selected_frames]\n",
    "    background = np.mean(background_frames, axis=0).astype(np.uint8)\n",
    "\n",
    "    return background\n",
    "\n",
    "def process_videos_in_strain(strain_folder, feature_name, average=True, num_videos=None, threshold_value=30):\n",
    "    \"\"\"\n",
    "    Process a specified number of videos in a strain folder and extract time series of a specific feature.\n",
    "    Optimized to use a single background frame per video.\n",
    "    \"\"\"\n",
    "    video_features = []\n",
    "    video_folders = sorted(glob.glob(os.path.join(strain_folder, '*/')))\n",
    "\n",
    "    if num_videos is not None:\n",
    "        video_folders = video_folders[:num_videos]\n",
    "\n",
    "    for video_folder in video_folders:\n",
    "        frame_statistics = []\n",
    "        \n",
    "        # Calculate the background once per video\n",
    "        background = subtract_background_from_video(video_folder)\n",
    "\n",
    "        for frame_path in sorted(glob.glob(os.path.join(video_folder, '*.jpg'))):\n",
    "            frame = read_image(frame_path, cv2.IMREAD_GRAYSCALE)\n",
    "            subtracted = cv2.absdiff(frame, background)  # Subtract the pre-calculated background\n",
    "            \n",
    "            segmented = segment_and_close_areas(subtracted, threshold_value)\n",
    "            frame_feature_data = calculate_features(segmented, frame_number=0, threshold_value=threshold_value)\n",
    "\n",
    "            feature_values = [prop[feature_name] for prop in frame_feature_data if feature_name in prop]\n",
    "\n",
    "            if feature_values:\n",
    "                frame_stat = {\n",
    "                    'mean': np.mean(feature_values),\n",
    "                    'percentile_25': np.percentile(feature_values, 25),\n",
    "                    'percentile_75': np.percentile(feature_values, 75)\n",
    "                }\n",
    "            else:\n",
    "                frame_stat = {'mean': None, 'percentile_25': None, 'percentile_75': None}\n",
    "\n",
    "            frame_statistics.append(frame_stat)\n",
    "\n",
    "        video_features.append(frame_statistics)\n",
    "\n",
    "    return video_features\n",
    "\n",
    "\n",
    "def plot_feature_time_series_plotly(strain_folder, feature_name='area', num_videos=None):\n",
    "    \"\"\"\n",
    "    Plot the mean values with shaded areas representing the 25th and 75th percentiles for a specified number of videos.\n",
    "    \"\"\"\n",
    "    time_series_data = process_videos_in_strain(strain_folder, feature_name, average=False, num_videos=num_videos)\n",
    "    folder_name = os.path.basename(os.path.normpath(strain_folder))\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    max_length = 0\n",
    "    colors = px.colors.qualitative.Plotly  # Using Plotly's qualitative color scale for variety\n",
    "\n",
    "    for i, video_stats in enumerate(time_series_data):\n",
    "        x_values = list(range(len(video_stats)))\n",
    "        max_length = max(max_length, len(x_values))\n",
    "\n",
    "        y_mean = [stat['mean'] for stat in video_stats]\n",
    "        y_25th = [stat['percentile_25'] for stat in video_stats]\n",
    "        y_75th = [stat['percentile_75'] for stat in video_stats]\n",
    "\n",
    "        color = colors[i % len(colors)]  # Cycle through colors\n",
    "\n",
    "        # fig.add_trace(go.Scatter(x=x_values+x_values[::-1], y=y_75th+y_25th[::-1], fill='toself',\n",
    "        #                          fillcolor=color.replace(')', ',0.1)').replace('rgb', 'rgba'),\n",
    "        #                          line=dict(color='rgba(255,255,255,0)'), name=f'Video {i+1} Percentiles', hoverinfo=\"skip\"))\n",
    "\n",
    "        fig.add_trace(go.Scatter(x=x_values, y=y_mean, mode='lines+markers', name=f'Video {i+1} Mean',\n",
    "                                 line=dict(color=color), showlegend=True))\n",
    "\n",
    "    fig.update_layout(title=f'Time Series of {feature_name} for Strain \"{folder_name}\"',\n",
    "                      xaxis_title='Frame Number',\n",
    "                      yaxis_title=f'{feature_name} Value',\n",
    "                      hovermode='closest',\n",
    "                      xaxis=dict(range=[0, max_length - 1]))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "strain_folder = '/Volumes/TOSHIBA_EXT/Phenotype_features_collective/Data/ExtractedFrames/da609'\n",
    "feature_name = 'blob_count'  # Adjust based on available features\n",
    "num_videos = 1  # For example, to plot the first 3 videos\n",
    "plot_feature_time_series_plotly(strain_folder, feature_name, num_videos=num_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violin Plots for Each Strain (Separate Experiments) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label, regionprops  # Ensure these are defined or imported correctly\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_feature_violin_plotly(strain_folder, feature_name='area'):\n",
    "    \"\"\"\n",
    "    Plot a series of violin plots with individual points for the distribution of average feature values per frame\n",
    "    for each video in the strain folder using plotly for interactivity.\n",
    "    \"\"\"\n",
    "    time_series_data = process_videos_in_strain(strain_folder, feature_name)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add a violin plot for each video, with individual points shown\n",
    "    for i, video_data in enumerate(time_series_data):\n",
    "        fig.add_trace(go.Violin(y=video_data,\n",
    "                                name=f'Video {i+1}',\n",
    "                                box_visible=True,\n",
    "                                meanline_visible=True,\n",
    "                                points='all',  # Show all individual points\n",
    "                                jitter=0.05,  # Add a slight jitter to the points to reduce overlap\n",
    "                                pointpos=0))  # Position the points on the violin plot\n",
    "    \n",
    "    fig.update_layout(title=f'Distribution of {feature_name} for Strain in {strain_folder}',\n",
    "                      yaxis_title=f'Average {feature_name} per Frame',\n",
    "                      xaxis_title='Video Number',\n",
    "                      hovermode='closest')\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "strain_folder = '/Volumes/TOSHIBA_EXT/Phenotype_features_collective/Data/ExtractedFrames/MY23'\n",
    "plot_feature_violin_plotly(strain_folder, feature_name='distance_from_center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Time Series for All Strains ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_time_series(experiment_features):\n",
    "    # Determine the number of unique features (excluding 'center_of_mass')\n",
    "    sample_experiment = next(iter(next(iter(experiment_features.values())).values()))\n",
    "    feature_keys = [key for key in sample_experiment[0].keys() if key != 'center_of_mass']\n",
    "\n",
    "    num_features = len(feature_keys)\n",
    "    fig, axs = plt.subplots(1, num_features, figsize=(15, 5), squeeze=False)\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for j, feature_key in enumerate(feature_keys):\n",
    "        for strain, experiments in experiment_features.items():\n",
    "            all_feature_values = []\n",
    "            for exp_label, features in experiments.items():\n",
    "                feature_values = [feature[feature_key] for feature in features]\n",
    "                all_feature_values.extend(feature_values)\n",
    "\n",
    "            avg_feature = np.mean(all_feature_values)\n",
    "            std_feature = np.std(all_feature_values)\n",
    "            x = range(len(all_feature_values))\n",
    "\n",
    "            axs[j].plot(x, [avg_feature] * len(x), label=strain)  # Constant line for average\n",
    "            axs[j].fill_between(x, [avg_feature - std_feature] * len(x), [avg_feature + std_feature] * len(x), alpha=0.2)\n",
    "\n",
    "        axs[j].set_title(feature_key.capitalize())\n",
    "        axs[j].set_xlabel('Experiment Index')\n",
    "        axs[j].set_ylabel(f'Average {feature_key.capitalize()}')\n",
    "        axs[j].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_average_time_series(experiment_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violin Plots Averaging Over All Experiments for All Strains ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_violin_plots_avg_all_experiments(experiment_features):\n",
    "    # Determine the number of unique features (excluding 'center_of_mass')\n",
    "    sample_experiment = next(iter(next(iter(experiment_features.values())).values()))\n",
    "    feature_keys = [key for key in sample_experiment[0].keys() if key != 'center_of_mass']\n",
    "\n",
    "    num_features = len(feature_keys)\n",
    "    fig, axs = plt.subplots(1, num_features, figsize=(15, 5), squeeze=False)\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for j, feature_key in enumerate(feature_keys):\n",
    "        feature_data = []\n",
    "\n",
    "        for strain, experiments in experiment_features.items():\n",
    "            all_feature_values = []\n",
    "            for exp_label, features in experiments.items():\n",
    "                feature_values = [feature[feature_key] for feature in features]\n",
    "                all_feature_values.extend(feature_values)\n",
    "            feature_data.append(all_feature_values)\n",
    "\n",
    "        sns.violinplot(data=feature_data, ax=axs[j])\n",
    "        axs[j].set_xticks(range(len(experiment_features)))\n",
    "        axs[j].set_xticklabels(experiment_features.keys(), rotation=45, ha='right')  # Rotate labels for better readability\n",
    "        axs[j].set_title(f\"Violin Plot of {feature_key.capitalize()} (Avg over All Experiments)\")\n",
    "        axs[j].set_ylabel(feature_key.capitalize())\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_violin_plots_avg_all_experiments(experiment_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No averaging #\n",
    "\n",
    "Checking if the average is a good summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Violin Plots for Each Video per Strain Showing Distribution of a Specific Feature ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def process_videos_in_strain(strain_folder, feature_name, average=True):\n",
    "    \"\"\"\n",
    "    Process all videos in a strain folder and extract time series of a specific feature.\n",
    "    \n",
    "    Parameters:\n",
    "    - strain_folder: Folder containing videos organized in subfolders.\n",
    "    - feature_name: The name of the feature to extract.\n",
    "    - average: Boolean indicating whether to average feature values over frames or collect all values.\n",
    "    \"\"\"\n",
    "    video_features = []  # List to hold the feature values for each video\n",
    "\n",
    "    for video_folder in sorted(glob.glob(os.path.join(strain_folder, '*/'))):\n",
    "        frame_features = []\n",
    "\n",
    "        for frame_path in sorted(glob.glob(os.path.join(video_folder, '*.jpg'))):\n",
    "            frame = read_image(frame_path, cv2.IMREAD_GRAYSCALE)\n",
    "            frame_feature_data = calculate_features(frame, frame_number=0)\n",
    "\n",
    "            # Extract and store the specific feature for each frame\n",
    "            feature_values = [prop[feature_name] for prop in frame_feature_data]\n",
    "\n",
    "            if average:\n",
    "                # Average feature for the frame\n",
    "                frame_features.append(np.mean(feature_values))\n",
    "            else:\n",
    "                # Collect all feature values from each frame\n",
    "                frame_features.extend(feature_values)  # Note the use of extend here\n",
    "\n",
    "        if average:\n",
    "            # If averaging, each entry in video_features is the average per frame for a video\n",
    "            video_features.append(frame_features)\n",
    "        else:\n",
    "            # If not averaging, each entry in video_features is a list of all feature values for a video\n",
    "            video_features.append(frame_features)\n",
    "\n",
    "    return video_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_violin_plotly(strain_folder, feature_name='area'):\n",
    "    \"\"\"\n",
    "    Plot a series of violin plots for the distribution of feature values detected in each frame\n",
    "    for each video in the strain folder using plotly for interactivity. Each point is a feature detected.\n",
    "    \"\"\"\n",
    "    # Ensure to collect non-averaged feature values from each frame\n",
    "    time_series_data = process_videos_in_strain(strain_folder, feature_name, average=False)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Iterate through the collected data to plot each video's feature distribution\n",
    "    for i, video_data in enumerate(time_series_data):\n",
    "        # Since we're not averaging, video_data contains all feature values directly\n",
    "        # Flatten the list if it's a list of lists to handle individual feature values\n",
    "        if isinstance(video_data, list) and all(isinstance(d, list) for d in video_data):\n",
    "            all_feature_values = [item for sublist in video_data for item in sublist]\n",
    "        else:\n",
    "            all_feature_values = video_data\n",
    "        \n",
    "        fig.add_trace(go.Violin(y=all_feature_values,\n",
    "                                name=f'Video {i+1}',\n",
    "                                box_visible=True,\n",
    "                                meanline_visible=True,\n",
    "                                points='all',  # Show all individual points\n",
    "                                jitter=0.05,  # Add a slight jitter to the points to reduce overlap\n",
    "                                pointpos=0))  # Position the points on the violin plot\n",
    "    \n",
    "    # Extract the name of the folder for the plot title\n",
    "    folder_name = os.path.basename(os.path.normpath(strain_folder))\n",
    "    \n",
    "    fig.update_layout(title=f'Feature \"{feature_name}\" Distribution in \"{folder_name}\"',\n",
    "                      yaxis_title=f'{feature_name} Value',\n",
    "                      xaxis_title='Video Number',\n",
    "                      hovermode='closest')\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "# Specify the folder and feature name\n",
    "strain_folder = '/Volumes/TOSHIBA_EXT/Phenotype_features_collective/Data/ExtractedFrames/da609'\n",
    "feature_name = 'blob_count'\n",
    "plot_feature_violin_plotly(strain_folder, feature_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Violin Plot per Strain Showing One Feature Across All Experiments ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This one takes some time so best to do it over night ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_all_strains(root_path, feature_name, average=False):\n",
    "#     \"\"\"\n",
    "#     Process videos across all strains in the root folder and collect feature values.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - root_path: The root folder containing strain subfolders.\n",
    "#     - feature_name: The feature to extract and plot.\n",
    "#     - average: Should be False to collect all values without averaging.\n",
    "    \n",
    "#     Returns:\n",
    "#     A dictionary with strain names as keys and lists of all feature values as values.\n",
    "#     \"\"\"\n",
    "#     strain_features = {}  # Dictionary to hold feature values for each strain\n",
    "\n",
    "#     for strain_folder in os.listdir(root_path):\n",
    "#         strain_path = os.path.join(root_path, strain_folder)\n",
    "#         if os.path.isdir(strain_path):\n",
    "#             # Process each strain and collect feature values\n",
    "#             video_features = process_videos_in_strain(strain_path, feature_name, average=average)\n",
    "#             # Flatten the list of lists to get a single list of all feature values for the strain\n",
    "#             all_features = [item for sublist in video_features for item in sublist]\n",
    "#             strain_features[strain_folder] = all_features\n",
    "\n",
    "#     return strain_features\n",
    "\n",
    "# def plot_feature_violin_all_strains(root_path, feature_name='area'):\n",
    "#     \"\"\"\n",
    "#     Plot violin plots for all strains, where each violin plot contains all feature values\n",
    "#     from all videos belonging to that strain, without averaging on each frame.\n",
    "#     \"\"\"\n",
    "#     strain_features = process_all_strains(root_path, feature_name, average=False)\n",
    "    \n",
    "#     fig = go.Figure()\n",
    "    \n",
    "#     for strain, features in strain_features.items():\n",
    "#         fig.add_trace(go.Violin(y=features,\n",
    "#                                 name=strain,\n",
    "#                                 box_visible=True,\n",
    "#                                 meanline_visible=True,\n",
    "#                                 points='all',\n",
    "#                                 jitter=0.05,\n",
    "#                                 pointpos=0))\n",
    "    \n",
    "#     fig.update_layout(title=f'Distribution of {feature_name} Across All Strains',\n",
    "#                       yaxis_title=f'{feature_name} Value',\n",
    "#                       xaxis_title='Strain',\n",
    "#                       hovermode='closest')\n",
    "    \n",
    "#     fig.show()\n",
    "\n",
    "# root_path = '/Volumes/TOSHIBA_EXT/Phenotype_features_collective/Data/ExtractedFrames'\n",
    "# feature_name = 'distance_from_center'\n",
    "# plot_feature_violin_all_strains(root_path, feature_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit to specific strains ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to limit the analysis to 3 strains to make things quicker: N2, da609 and CB4856. I will then prolong this to the rest of the strains if we see something interesting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_strains(root_path, feature_name, average=False):\n",
    "    \"\"\"\n",
    "    Process videos across specified strains in the root folder and collect feature values.\n",
    "    \n",
    "    Parameters:\n",
    "    - root_path: The root folder containing strain subfolders.\n",
    "    - feature_name: The feature to extract and plot.\n",
    "    - average: Should be False to collect all values without averaging.\n",
    "    \n",
    "    Returns:\n",
    "    A dictionary with specified strain names as keys and lists of all feature values as values.\n",
    "    \"\"\"\n",
    "    strain_features = {}  # Dictionary to hold feature values for each specified strain\n",
    "    # List of specified strains to process\n",
    "    specified_strains = ['CB4856', 'N2', 'da609']\n",
    "\n",
    "    for strain_folder in specified_strains:\n",
    "        strain_path = os.path.join(root_path, strain_folder)\n",
    "        if os.path.isdir(strain_path):\n",
    "            # Process each specified strain and collect feature values\n",
    "            video_features = process_videos_in_strain(strain_path, feature_name, average=average)\n",
    "            # Flatten the list of lists to get a single list of all feature values for the strain\n",
    "            all_features = [item for sublist in video_features for item in sublist]\n",
    "            strain_features[strain_folder] = all_features\n",
    "\n",
    "    return strain_features\n",
    "\n",
    "def plot_feature_violin_all_strains(root_path, feature_name='area'):\n",
    "    \"\"\"\n",
    "    Plot violin plots for specified strains, where each violin plot contains all feature values\n",
    "    from all videos belonging to that strain, without averaging on each frame.\n",
    "    \"\"\"\n",
    "    strain_features = process_all_strains(root_path, feature_name, average=False)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for strain, features in strain_features.items():\n",
    "        fig.add_trace(go.Violin(y=features,\n",
    "                                name=strain,\n",
    "                                box_visible=True,\n",
    "                                meanline_visible=True,\n",
    "                                points='all',\n",
    "                                jitter=0.05,\n",
    "                                pointpos=0))\n",
    "    \n",
    "    fig.update_layout(title=f'Distribution of {feature_name} Across Specified Strains',\n",
    "                      yaxis_title=f'{feature_name} Value',\n",
    "                      xaxis_title='Strain',\n",
    "                      hovermode='closest')\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "# Specify the root path and feature name\n",
    "root_path = '/Volumes/TOSHIBA_EXT/Phenotype_features_collective/Data/ExtractedFrames'\n",
    "feature_name = 'blob_count'\n",
    "plot_feature_violin_all_strains(root_path, feature_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Violin Plot Combining All Videos and All Strains Together ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_distribution_across_strains(root_path, feature_name='area'):\n",
    "    \"\"\"\n",
    "    Plot a violin plot for the distribution of feature values across all strains and videos.\n",
    "    \"\"\"\n",
    "    all_strains_values = []\n",
    "    \n",
    "    for strain_folder in os.listdir(root_path):\n",
    "        strain_path = os.path.join(root_path, strain_folder)\n",
    "        if os.path.isdir(strain_path):\n",
    "            time_series_data = process_videos_in_strain(strain_path, feature_name, average=False)\n",
    "            all_strains_values.extend([np.concatenate(video_data).ravel() for video_data in time_series_data])\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Aggregating all frame values across all strains and videos\n",
    "    all_values = np.concatenate(all_strains_values)\n",
    "    fig.add_trace(go.Violin(y=all_values,\n",
    "                            name=\"All Strains\",\n",
    "                            points='all',\n",
    "                            jitter=0.1,\n",
    "                            pointpos=0))\n",
    "    \n",
    "    fig.update_layout(title=f'Distribution of {feature_name} Across All Strains and Videos',\n",
    "                      yaxis_title=feature_name,\n",
    "                      xaxis_title='Aggregate of All Strains and Videos')\n",
    "    \n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collectiveNematode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
