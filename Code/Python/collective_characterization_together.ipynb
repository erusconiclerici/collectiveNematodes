{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.draw import circle_perimeter\n",
    "from math import sqrt\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.filters import threshold_otsu\n",
    "from tabulate import tabulate\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rcParams\n",
    "import h5py    # for reading HDF5 files \n",
    "import cv2     # for image conversion\n",
    "import re    # use it to sort but not sure what it is!\n",
    "from scipy.stats import zscore\n",
    "from skimage import draw, measure\n",
    "import pywt\n",
    "from scipy.spatial.distance import cdist\n",
    "import seaborn as sns\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.colors as colors\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage import color\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set infromation overview: ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Divergent Sets:\n",
    "\n",
    "    Consists of 12 genotypically distinct strains. These are strains that are further apart on the phenotypic tree. \n",
    "    Ideal for determining broad-sense heritability with repeated measurements of specific phenotypes.\n",
    "    This allows us to look into the relationship between the behavior and the genetic makeup. \n",
    "\n",
    "2. Mapping Sets:\n",
    "\n",
    "    Comprises 48 strains suitable for collecting phenotype data for broad diversity or genome-wide association studies.\n",
    "    Using multiple strain sets can enhance the statistical strength in genome-wide association studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipline: ###\n",
    "\n",
    "1. Take hdf5 tierpsy output and extract frames\n",
    "\n",
    "ATTENTION: change the output_root_path depending on which data set you are using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label_from_path(file_path):\n",
    "    # Get the base file name\n",
    "    base_name = os.path.basename(file_path)\n",
    "    \n",
    "    try:\n",
    "        # Find the position of the first underscore after the 6th character\n",
    "        first_underscore_pos = base_name.index('_', 6)\n",
    "        \n",
    "        # Extract the label from the 6th character to the first underscore\n",
    "        label_strain = base_name[6:first_underscore_pos]\n",
    "        \n",
    "        return label_strain\n",
    "    except ValueError:\n",
    "        return \"Unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing single strains all videos ###\n",
    "\n",
    "1. Keeping all frames sepearated\n",
    "\n",
    "2. Putting all frames from all videos in same folder for analysis \n",
    "\n",
    "Extract frames from each hdf5 file: \n",
    "\n",
    "\n",
    "This code snippet is designed to process a series of HDF5 files, specifically for extracting and saving image data:\n",
    "\n",
    "1. Iterate Over HDF5 Files: The for loop iterates over a list of file paths (hdf5_file_paths).\n",
    "\n",
    "2. Open HDF5 File: Inside the loop, each file is opened using h5py.File.\n",
    "\n",
    "3. Access Image Dataset: The script accesses a dataset named /mask within each HDF5 file. This dataset presumably contains image data. Information about the dataset, like its shape and data type, is printed out.\n",
    "\n",
    "4. Frame Extraction Step: A variable step is set, which determines the interval at which frames (or elements) from the dataset will be extracted. In this code, it's set to 500, meaning every 500th frame will be considered.\n",
    "\n",
    "5. Output Directory Preparation: For each HDF5 file, an output directory is created to store the extracted images. This directory is based on the name of the HDF5 file and is located within a root output path (output_root_path).\n",
    "\n",
    "6. Create Directory If Necessary: The script checks if the output directory already exists. If it doesn't, it creates the directory using os.makedirs.\n",
    "\n",
    "7. Extract and Save Frames: Another loop iterates through the image dataset (img_ds2), jumping step frames at a time. Each selected frame is saved as a JPEG image. The naming convention for these images is based on their index in the dataset, formatted to have six digits with leading zeros if necessary.\n",
    "\n",
    "This code is useful for batch processing HDF5 files containing image data, particularly when you only need to extract and save certain frames (e.g., for donsampling or reducing data size)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_directory_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def extract_frames_from_hdf5(file_paths, output_directories, step=500):\n",
    "    for path in file_paths:\n",
    "        with h5py.File(path, 'r') as hdf:\n",
    "            img_ds2 = hdf['/mask']\n",
    "            print(f'Image Dataset info: Shape={img_ds2.shape}, Dtype={img_ds2.dtype}')\n",
    "            for i in range(0, img_ds2.shape[0], step):\n",
    "                name = \"{:06d}.jpg\".format(i)\n",
    "                cv2.imwrite(os.path.join(output_directories[path], name), img_ds2[i, :])\n",
    "\n",
    "def load_images_from_folder(main_folder, every_jth_image=10):\n",
    "    all_images = []\n",
    "    # Get all subdirectories in the main folder\n",
    "    subfolders = [os.path.join(main_folder, d) for d in os.listdir(main_folder) if os.path.isdir(os.path.join(main_folder, d))]\n",
    "\n",
    "    for folder in subfolders:\n",
    "        imagefiles = [f for f in os.listdir(folder) if f.endswith(\".jpg\")]\n",
    "        imagefiles.sort()\n",
    "\n",
    "        print(f\"Found {len(imagefiles)} image files in {folder}\")\n",
    "\n",
    "        for ii in range(0, len(imagefiles), every_jth_image):\n",
    "            currentfilename = imagefiles[ii]\n",
    "            filepath = os.path.join(folder, currentfilename)\n",
    "            currentimage = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if currentimage is not None:\n",
    "                all_images.append(currentimage)\n",
    "            else:\n",
    "                print(f\"Failed to load image: {filepath}\")\n",
    "\n",
    "    return all_images\n",
    "\n",
    "# Load images from subfolders\n",
    "all_images = load_images_from_folder(output_root_path)\n",
    "print(\"Total number of images loaded from all subfolders: \", len(all_images))\n",
    "\n",
    "\n",
    "\n",
    "# Set paths\n",
    "hdf5_folder_path = r'/Volumes/TOSHIBA_EXT/Phenotype_features_collective/Data/CB4856'\n",
    "output_root_path = os.path.join(hdf5_folder_path, 'framesExtracted')\n",
    "\n",
    "# Ensure the output root folder exists\n",
    "ensure_directory_exists(output_root_path)\n",
    "\n",
    "# Ensure the output root folder exists\n",
    "if not os.path.exists(output_root_path):\n",
    "    os.makedirs(output_root_path)\n",
    "\n",
    "# Get HDF5 file paths and create output directories\n",
    "hdf5_file_paths = glob.glob(os.path.join(hdf5_folder_path, '*.hdf5'))\n",
    "output_directories = create_output_directories(hdf5_file_paths, output_root_path)\n",
    "\n",
    "# Extract frames from HDF5 files\n",
    "extract_frames_from_hdf5(hdf5_file_paths, output_directories)\n",
    "\n",
    "# Load images\n",
    "all_images = load_images_from_folder(output_root_path)\n",
    "print(\"Total number of images loaded: \", len(all_images))\n",
    "\n",
    "# PLOT FRAMES FROM VIDEO \n",
    "\n",
    "# Loop through each list of images\n",
    "for idx, video_images in enumerate(all_images):\n",
    "    num_frames = len(video_images)\n",
    "    \n",
    "    # Skip if no images are loaded\n",
    "    if num_frames == 0:\n",
    "        print(f\"No images to display for index {idx}.\")\n",
    "        continue\n",
    "\n",
    "    # Calculate the number of rows and columns for the subplot\n",
    "    num_cols = 5\n",
    "    num_rows = int(np.ceil(num_frames / num_cols))\n",
    "\n",
    "    # Create a new figure for each video\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 15))\n",
    "    axs = np.ravel(axs)\n",
    "\n",
    "    # Get the file path corresponding to the current set of images\n",
    "    file_path = hdf5_file_paths[idx]\n",
    "    label_file = labels_strain_list[file_path]\n",
    "\n",
    "    # Set the title for the figure using the label\n",
    "    fig.suptitle(f\"Video from {label_file}\", fontsize=16)\n",
    "\n",
    "    # Plot each frame\n",
    "    for i in range(num_rows * num_cols):\n",
    "        if i < num_frames:\n",
    "            if video_images[i].ndim == 2:  # Check if the image is 2D\n",
    "                axs[i].imshow(video_images[i], cmap='gray')\n",
    "                axs[i].axis('off')\n",
    "            else:\n",
    "                print(f\"Image at index {i} is not 2D. Shape: {video_images[i].shape}\")\n",
    "        else:\n",
    "            axs[i].axis('off')  # Turn off extra subplots\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to make room for title\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
